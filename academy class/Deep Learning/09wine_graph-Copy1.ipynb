{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d4c55f-f5c3-499f-9ed5-24a4598a0d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5543a71c-321b-402b-837a-be63020fc75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f9577c2-a884-4863-ab39-6339987cf5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3a385ca-32ed-4b97-99ed-aa6579d46ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_pre.sample(frac=1)\n",
    "df_pre = pd.read_csv('data/wine.csv')\n",
    "df = df_pre.sample(frac=0.5)  # 전체 데이터에서 샘플을 가져온다. 1= 100%, 0.7 = 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "636632a1-32c2-4949-b6e1-39325dd69926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: red wine, 0: white wine\n",
    "# 1과 0을 구분하는 회귀, 바이너리 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f8cbeb0-ecad-4d9c-89c3-426068da3c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "dataset = df.values\n",
    "print(dataset.dtype)\n",
    "# 전체가 float 이므로 형변환 불필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "201cb764-ac98-4355-bef9-e18e9f7f34d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:, :12]\n",
    "Y = dataset[:, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "096e701d-a36a-44a8-aa28-baca7810ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59cfc710-1084-46fd-8332-1e479cb58a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                390       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                372       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 875\n",
      "Trainable params: 875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e92464-7239-473e-acce-8d9a8af5aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수 및 optimize 연걸\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff452ab0-9442-44ae-a808-1ed6ebbe8549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR) :  # 같은 파일명이 존재하는지 확인\n",
    "    os.mkdir(MODEL_DIR)   # 모델 생성\n",
    "    \n",
    "\n",
    "modelpath = './model/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True) # 체크포인트 생성, 무엇을 체크할 것인지 지정(mointor)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100) \n",
    "# 상태가 좋아지지 않으면 100번까지 참고, 그래도 loss 값이 좋아지지 않으면 자동으로 정지. 만약 값이 좋아지면 그 순간부터 다시 0부터 카운드 한다. \n",
    "\n",
    "# monitor=val_loss : 무엇을 체크할 것인지 지정. val_loss 를 관찰하라는 뜻\n",
    "# verbose=1 : 중간 과정을 계속 출력하라\n",
    "# save_best_only=True : 모델이 향상될 때만 저장하라 \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c614216b-2e58-460a-9c37-ebc78f5d5bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X, Y, validation_split=0.2, epochs=3500, batch_size=500, verbose=0, callbacks=[checkpointer,early_stopping])\n",
    "\n",
    "# validation_split=0.2 : 20% 를 뗴어놓고, 80%만 훈련시킨 후, 나머지 20% 를 validate을 해주고, 그때마다 그 값을 나타내 보여달라\n",
    "# verbose=0 : 출력 값을 보이지 마라\n",
    "# print(\"Accuracy:  %.4f\" % (model.evaluate(X, Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6ffc72a-30c6-4e08-a9c3-cac6de4edbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.78239, saving model to ./model/01-0.7824.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.78239 to 0.69160, saving model to ./model/02-0.6916.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.69160 to 0.50391, saving model to ./model/03-0.5039.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.50391 to 0.48676, saving model to ./model/04-0.4868.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.48676 to 0.38270, saving model to ./model/05-0.3827.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.38270 to 0.38249, saving model to ./model/06-0.3825.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.38249 to 0.33495, saving model to ./model/07-0.3349.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.33495 to 0.32274, saving model to ./model/08-0.3227.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.32274 to 0.29794, saving model to ./model/09-0.2979.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.29794 to 0.28895, saving model to ./model/10-0.2889.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.28895 to 0.27448, saving model to ./model/11-0.2745.hdf5\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.27448 to 0.26683, saving model to ./model/12-0.2668.hdf5\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.26683 to 0.25854, saving model to ./model/13-0.2585.hdf5\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.25854 to 0.25321, saving model to ./model/14-0.2532.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.25321 to 0.24667, saving model to ./model/15-0.2467.hdf5\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.24667 to 0.24169, saving model to ./model/16-0.2417.hdf5\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.24169 to 0.23802, saving model to ./model/17-0.2380.hdf5\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.23802 to 0.23421, saving model to ./model/18-0.2342.hdf5\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.23421 to 0.22934, saving model to ./model/19-0.2293.hdf5\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.22934 to 0.22603, saving model to ./model/20-0.2260.hdf5\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.22603 to 0.22475, saving model to ./model/21-0.2248.hdf5\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.22475 to 0.22399, saving model to ./model/22-0.2240.hdf5\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.22399 to 0.22012, saving model to ./model/23-0.2201.hdf5\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.22012 to 0.21888, saving model to ./model/24-0.2189.hdf5\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.21888 to 0.21734, saving model to ./model/25-0.2173.hdf5\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.21734 to 0.21691, saving model to ./model/26-0.2169.hdf5\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.21691 to 0.21540, saving model to ./model/27-0.2154.hdf5\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.21540 to 0.21378, saving model to ./model/28-0.2138.hdf5\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.21378 to 0.21271, saving model to ./model/29-0.2127.hdf5\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.21271 to 0.21140, saving model to ./model/30-0.2114.hdf5\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.21140 to 0.20988, saving model to ./model/31-0.2099.hdf5\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.20988 to 0.20869, saving model to ./model/32-0.2087.hdf5\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.20869\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.20869 to 0.20605, saving model to ./model/34-0.2060.hdf5\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.20605 to 0.20294, saving model to ./model/35-0.2029.hdf5\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.20294 to 0.20127, saving model to ./model/36-0.2013.hdf5\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.20127\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.20127 to 0.19893, saving model to ./model/38-0.1989.hdf5\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.19893 to 0.19774, saving model to ./model/39-0.1977.hdf5\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.19774 to 0.19679, saving model to ./model/40-0.1968.hdf5\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.19679 to 0.19577, saving model to ./model/41-0.1958.hdf5\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.19577 to 0.19506, saving model to ./model/42-0.1951.hdf5\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.19506 to 0.19314, saving model to ./model/43-0.1931.hdf5\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.19314 to 0.19181, saving model to ./model/44-0.1918.hdf5\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.19181 to 0.19149, saving model to ./model/45-0.1915.hdf5\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.19149\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.19149 to 0.18945, saving model to ./model/47-0.1895.hdf5\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.18945 to 0.18908, saving model to ./model/48-0.1891.hdf5\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.18908\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.18908 to 0.18705, saving model to ./model/50-0.1870.hdf5\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.18705 to 0.18628, saving model to ./model/51-0.1863.hdf5\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.18628\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.18628 to 0.18495, saving model to ./model/53-0.1849.hdf5\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.18495 to 0.18375, saving model to ./model/54-0.1838.hdf5\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.18375 to 0.18319, saving model to ./model/55-0.1832.hdf5\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.18319 to 0.18236, saving model to ./model/56-0.1824.hdf5\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.18236 to 0.18157, saving model to ./model/57-0.1816.hdf5\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.18157 to 0.18083, saving model to ./model/58-0.1808.hdf5\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.18083 to 0.18021, saving model to ./model/59-0.1802.hdf5\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.18021\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.18021 to 0.17912, saving model to ./model/61-0.1791.hdf5\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.17912 to 0.17859, saving model to ./model/62-0.1786.hdf5\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.17859 to 0.17771, saving model to ./model/63-0.1777.hdf5\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.17771\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.17771 to 0.17678, saving model to ./model/65-0.1768.hdf5\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.17678 to 0.17594, saving model to ./model/66-0.1759.hdf5\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.17594\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.17594 to 0.17460, saving model to ./model/68-0.1746.hdf5\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.17460 to 0.17366, saving model to ./model/69-0.1737.hdf5\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.17366 to 0.17317, saving model to ./model/70-0.1732.hdf5\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.17317 to 0.17280, saving model to ./model/71-0.1728.hdf5\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.17280\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.17280 to 0.17128, saving model to ./model/73-0.1713.hdf5\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.17128 to 0.17116, saving model to ./model/74-0.1712.hdf5\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.17116 to 0.17012, saving model to ./model/75-0.1701.hdf5\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.17012 to 0.16956, saving model to ./model/76-0.1696.hdf5\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.16956 to 0.16903, saving model to ./model/77-0.1690.hdf5\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.16903\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.16903 to 0.16781, saving model to ./model/79-0.1678.hdf5\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.16781 to 0.16748, saving model to ./model/80-0.1675.hdf5\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.16748\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.16748 to 0.16698, saving model to ./model/82-0.1670.hdf5\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.16698 to 0.16617, saving model to ./model/83-0.1662.hdf5\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.16617 to 0.16539, saving model to ./model/84-0.1654.hdf5\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.16539 to 0.16539, saving model to ./model/85-0.1654.hdf5\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.16539 to 0.16381, saving model to ./model/86-0.1638.hdf5\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.16381 to 0.16333, saving model to ./model/87-0.1633.hdf5\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.16333 to 0.16272, saving model to ./model/88-0.1627.hdf5\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.16272 to 0.16231, saving model to ./model/89-0.1623.hdf5\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.16231\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.16231 to 0.16180, saving model to ./model/91-0.1618.hdf5\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.16180 to 0.16102, saving model to ./model/92-0.1610.hdf5\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.16102 to 0.16091, saving model to ./model/93-0.1609.hdf5\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.16091 to 0.16005, saving model to ./model/94-0.1600.hdf5\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.16005 to 0.15861, saving model to ./model/95-0.1586.hdf5\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.15861\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.15861 to 0.15742, saving model to ./model/97-0.1574.hdf5\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.15742 to 0.15710, saving model to ./model/98-0.1571.hdf5\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.15710\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.15710 to 0.15595, saving model to ./model/100-0.1560.hdf5\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.15595 to 0.15566, saving model to ./model/101-0.1557.hdf5\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.15566 to 0.15460, saving model to ./model/102-0.1546.hdf5\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.15460 to 0.15403, saving model to ./model/103-0.1540.hdf5\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.15403\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.15403 to 0.15307, saving model to ./model/105-0.1531.hdf5\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.15307 to 0.15288, saving model to ./model/106-0.1529.hdf5\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.15288 to 0.15153, saving model to ./model/107-0.1515.hdf5\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.15153 to 0.15116, saving model to ./model/108-0.1512.hdf5\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.15116 to 0.15000, saving model to ./model/109-0.1500.hdf5\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.15000 to 0.14971, saving model to ./model/110-0.1497.hdf5\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.14971 to 0.14847, saving model to ./model/111-0.1485.hdf5\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.14847 to 0.14787, saving model to ./model/112-0.1479.hdf5\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.14787 to 0.14709, saving model to ./model/113-0.1471.hdf5\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.14709 to 0.14621, saving model to ./model/114-0.1462.hdf5\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.14621\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.14621 to 0.14434, saving model to ./model/116-0.1443.hdf5\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.14434 to 0.14391, saving model to ./model/117-0.1439.hdf5\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.14391 to 0.14240, saving model to ./model/118-0.1424.hdf5\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.14240 to 0.14167, saving model to ./model/119-0.1417.hdf5\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.14167 to 0.14066, saving model to ./model/120-0.1407.hdf5\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.14066\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.14066\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.14066 to 0.13871, saving model to ./model/123-0.1387.hdf5\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.13871 to 0.13851, saving model to ./model/124-0.1385.hdf5\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.13851 to 0.13675, saving model to ./model/125-0.1368.hdf5\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.13675\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.13675\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.13675 to 0.13495, saving model to ./model/128-0.1350.hdf5\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.13495 to 0.13433, saving model to ./model/129-0.1343.hdf5\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.13433 to 0.13346, saving model to ./model/130-0.1335.hdf5\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.13346 to 0.13288, saving model to ./model/131-0.1329.hdf5\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.13288 to 0.13276, saving model to ./model/132-0.1328.hdf5\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.13276 to 0.13129, saving model to ./model/133-0.1313.hdf5\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.13129 to 0.13084, saving model to ./model/134-0.1308.hdf5\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.13084 to 0.13062, saving model to ./model/135-0.1306.hdf5\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.13062 to 0.12917, saving model to ./model/136-0.1292.hdf5\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.12917 to 0.12848, saving model to ./model/137-0.1285.hdf5\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.12848 to 0.12798, saving model to ./model/138-0.1280.hdf5\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.12798\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.12798 to 0.12662, saving model to ./model/140-0.1266.hdf5\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.12662 to 0.12614, saving model to ./model/141-0.1261.hdf5\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.12614 to 0.12564, saving model to ./model/142-0.1256.hdf5\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.12564\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.12564 to 0.12473, saving model to ./model/144-0.1247.hdf5\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.12473\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.12473 to 0.12338, saving model to ./model/146-0.1234.hdf5\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.12338 to 0.12269, saving model to ./model/147-0.1227.hdf5\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.12269 to 0.12221, saving model to ./model/148-0.1222.hdf5\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.12221\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.12221 to 0.12113, saving model to ./model/150-0.1211.hdf5\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.12113\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.12113 to 0.12039, saving model to ./model/152-0.1204.hdf5\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.12039 to 0.12021, saving model to ./model/153-0.1202.hdf5\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.12021 to 0.11909, saving model to ./model/154-0.1191.hdf5\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.11909 to 0.11872, saving model to ./model/155-0.1187.hdf5\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.11872 to 0.11825, saving model to ./model/156-0.1182.hdf5\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.11825 to 0.11795, saving model to ./model/157-0.1179.hdf5\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.11795 to 0.11745, saving model to ./model/158-0.1174.hdf5\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.11745 to 0.11704, saving model to ./model/159-0.1170.hdf5\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.11704 to 0.11646, saving model to ./model/160-0.1165.hdf5\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.11646 to 0.11590, saving model to ./model/161-0.1159.hdf5\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.11590 to 0.11549, saving model to ./model/162-0.1155.hdf5\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.11549\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.11549 to 0.11457, saving model to ./model/164-0.1146.hdf5\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.11457\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.11457 to 0.11435, saving model to ./model/166-0.1144.hdf5\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.11435\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.11435 to 0.11383, saving model to ./model/168-0.1138.hdf5\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.11383 to 0.11360, saving model to ./model/169-0.1136.hdf5\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.11360 to 0.11259, saving model to ./model/170-0.1126.hdf5\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.11259 to 0.11232, saving model to ./model/171-0.1123.hdf5\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.11232 to 0.11159, saving model to ./model/172-0.1116.hdf5\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.11159 to 0.11133, saving model to ./model/173-0.1113.hdf5\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.11133 to 0.11122, saving model to ./model/174-0.1112.hdf5\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.11122 to 0.11111, saving model to ./model/175-0.1111.hdf5\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.11111 to 0.11019, saving model to ./model/176-0.1102.hdf5\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.11019\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.11019 to 0.10972, saving model to ./model/178-0.1097.hdf5\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.10972\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.10972\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.10972\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.10972\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.10972 to 0.10812, saving model to ./model/183-0.1081.hdf5\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.10812 to 0.10793, saving model to ./model/184-0.1079.hdf5\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.10793 to 0.10773, saving model to ./model/185-0.1077.hdf5\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.10773 to 0.10752, saving model to ./model/186-0.1075.hdf5\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.10752 to 0.10710, saving model to ./model/187-0.1071.hdf5\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.10710 to 0.10682, saving model to ./model/188-0.1068.hdf5\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.10682 to 0.10636, saving model to ./model/189-0.1064.hdf5\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.10636\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.10636\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.10636\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.10636 to 0.10511, saving model to ./model/193-0.1051.hdf5\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.10511\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.10511\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.10511\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.10511 to 0.10483, saving model to ./model/197-0.1048.hdf5\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.10483 to 0.10394, saving model to ./model/198-0.1039.hdf5\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.10394 to 0.10278, saving model to ./model/199-0.1028.hdf5\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.10278\n",
      "\n",
      "Epoch 00201: val_loss improved from 0.10278 to 0.10221, saving model to ./model/201-0.1022.hdf5\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.10221\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.10221 to 0.10213, saving model to ./model/203-0.1021.hdf5\n",
      "\n",
      "Epoch 00204: val_loss improved from 0.10213 to 0.10209, saving model to ./model/204-0.1021.hdf5\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.10209 to 0.10207, saving model to ./model/205-0.1021.hdf5\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.10207\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.10207\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.10207\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.10207\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.10207\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.10207\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.10207\n",
      "\n",
      "Epoch 00213: val_loss improved from 0.10207 to 0.10154, saving model to ./model/213-0.1015.hdf5\n",
      "\n",
      "Epoch 00214: val_loss improved from 0.10154 to 0.10115, saving model to ./model/214-0.1011.hdf5\n",
      "\n",
      "Epoch 00215: val_loss improved from 0.10115 to 0.09892, saving model to ./model/215-0.0989.hdf5\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.09892\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.09892\n",
      "\n",
      "Epoch 00218: val_loss improved from 0.09892 to 0.09874, saving model to ./model/218-0.0987.hdf5\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.09874\n",
      "\n",
      "Epoch 00220: val_loss improved from 0.09874 to 0.09847, saving model to ./model/220-0.0985.hdf5\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.09847\n",
      "\n",
      "Epoch 00222: val_loss improved from 0.09847 to 0.09753, saving model to ./model/222-0.0975.hdf5\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.09753\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.09753\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.09753\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.09753 to 0.09670, saving model to ./model/226-0.0967.hdf5\n",
      "\n",
      "Epoch 00227: val_loss improved from 0.09670 to 0.09655, saving model to ./model/227-0.0965.hdf5\n",
      "\n",
      "Epoch 00228: val_loss improved from 0.09655 to 0.09596, saving model to ./model/228-0.0960.hdf5\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.09596 to 0.09584, saving model to ./model/229-0.0958.hdf5\n",
      "\n",
      "Epoch 00230: val_loss improved from 0.09584 to 0.09579, saving model to ./model/230-0.0958.hdf5\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.09579\n",
      "\n",
      "Epoch 00232: val_loss improved from 0.09579 to 0.09552, saving model to ./model/232-0.0955.hdf5\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.09552\n",
      "\n",
      "Epoch 00234: val_loss improved from 0.09552 to 0.09523, saving model to ./model/234-0.0952.hdf5\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.09523\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.09523\n",
      "\n",
      "Epoch 00237: val_loss improved from 0.09523 to 0.09486, saving model to ./model/237-0.0949.hdf5\n",
      "\n",
      "Epoch 00238: val_loss improved from 0.09486 to 0.09390, saving model to ./model/238-0.0939.hdf5\n",
      "\n",
      "Epoch 00239: val_loss improved from 0.09390 to 0.09347, saving model to ./model/239-0.0935.hdf5\n",
      "\n",
      "Epoch 00240: val_loss improved from 0.09347 to 0.09319, saving model to ./model/240-0.0932.hdf5\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.09319\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.09319\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.09319\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.09319\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.09319\n",
      "\n",
      "Epoch 00246: val_loss improved from 0.09319 to 0.09244, saving model to ./model/246-0.0924.hdf5\n",
      "\n",
      "Epoch 00247: val_loss improved from 0.09244 to 0.09222, saving model to ./model/247-0.0922.hdf5\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.09222\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.09222\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.09222\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.09222\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.09222\n",
      "\n",
      "Epoch 00253: val_loss improved from 0.09222 to 0.09143, saving model to ./model/253-0.0914.hdf5\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.09143\n",
      "\n",
      "Epoch 00255: val_loss improved from 0.09143 to 0.09068, saving model to ./model/255-0.0907.hdf5\n",
      "\n",
      "Epoch 00256: val_loss improved from 0.09068 to 0.09062, saving model to ./model/256-0.0906.hdf5\n",
      "\n",
      "Epoch 00257: val_loss improved from 0.09062 to 0.09023, saving model to ./model/257-0.0902.hdf5\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.09023\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.09023\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.09023\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.09023\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.09023\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.09023\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.09023\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.09023\n",
      "\n",
      "Epoch 00266: val_loss improved from 0.09023 to 0.08984, saving model to ./model/266-0.0898.hdf5\n",
      "\n",
      "Epoch 00267: val_loss improved from 0.08984 to 0.08869, saving model to ./model/267-0.0887.hdf5\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.08869\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.08869\n",
      "\n",
      "Epoch 00270: val_loss improved from 0.08869 to 0.08839, saving model to ./model/270-0.0884.hdf5\n",
      "\n",
      "Epoch 00271: val_loss improved from 0.08839 to 0.08821, saving model to ./model/271-0.0882.hdf5\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.08821\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.08821\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.08821\n",
      "\n",
      "Epoch 00275: val_loss improved from 0.08821 to 0.08792, saving model to ./model/275-0.0879.hdf5\n",
      "\n",
      "Epoch 00276: val_loss improved from 0.08792 to 0.08778, saving model to ./model/276-0.0878.hdf5\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.08778\n",
      "\n",
      "Epoch 00278: val_loss improved from 0.08778 to 0.08736, saving model to ./model/278-0.0874.hdf5\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.08736\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.08736\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.08736\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.08736\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.08736\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.08736\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.08736\n",
      "\n",
      "Epoch 00286: val_loss improved from 0.08736 to 0.08555, saving model to ./model/286-0.0856.hdf5\n",
      "\n",
      "Epoch 00287: val_loss improved from 0.08555 to 0.08553, saving model to ./model/287-0.0855.hdf5\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.08553\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.08553\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.08553\n",
      "\n",
      "Epoch 00291: val_loss improved from 0.08553 to 0.08533, saving model to ./model/291-0.0853.hdf5\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.08533\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.08533\n",
      "\n",
      "Epoch 00294: val_loss improved from 0.08533 to 0.08426, saving model to ./model/294-0.0843.hdf5\n",
      "\n",
      "Epoch 00295: val_loss improved from 0.08426 to 0.08388, saving model to ./model/295-0.0839.hdf5\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.08388\n",
      "\n",
      "Epoch 00297: val_loss improved from 0.08388 to 0.08379, saving model to ./model/297-0.0838.hdf5\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.08379\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.08379\n",
      "\n",
      "Epoch 00300: val_loss improved from 0.08379 to 0.08339, saving model to ./model/300-0.0834.hdf5\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.08339\n",
      "\n",
      "Epoch 00302: val_loss improved from 0.08339 to 0.08320, saving model to ./model/302-0.0832.hdf5\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.08320\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.08320\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.08320\n",
      "\n",
      "Epoch 00306: val_loss improved from 0.08320 to 0.08274, saving model to ./model/306-0.0827.hdf5\n",
      "\n",
      "Epoch 00307: val_loss improved from 0.08274 to 0.08267, saving model to ./model/307-0.0827.hdf5\n",
      "\n",
      "Epoch 00308: val_loss improved from 0.08267 to 0.08220, saving model to ./model/308-0.0822.hdf5\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.08220\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.08220\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.08220\n",
      "\n",
      "Epoch 00312: val_loss improved from 0.08220 to 0.08109, saving model to ./model/312-0.0811.hdf5\n",
      "\n",
      "Epoch 00313: val_loss improved from 0.08109 to 0.08100, saving model to ./model/313-0.0810.hdf5\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.08100\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.08100\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.08100\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.08100\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.08100\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.08100\n",
      "\n",
      "Epoch 00320: val_loss improved from 0.08100 to 0.08095, saving model to ./model/320-0.0809.hdf5\n",
      "\n",
      "Epoch 00321: val_loss improved from 0.08095 to 0.08044, saving model to ./model/321-0.0804.hdf5\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.08044\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.08044\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.08044\n",
      "\n",
      "Epoch 00325: val_loss improved from 0.08044 to 0.07968, saving model to ./model/325-0.0797.hdf5\n",
      "\n",
      "Epoch 00326: val_loss improved from 0.07968 to 0.07964, saving model to ./model/326-0.0796.hdf5\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.07964\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.07964\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.07964\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.07964\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.07964\n",
      "\n",
      "Epoch 00332: val_loss improved from 0.07964 to 0.07864, saving model to ./model/332-0.0786.hdf5\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.07864\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.07864\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.07864\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.07864\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.07864\n",
      "\n",
      "Epoch 00338: val_loss improved from 0.07864 to 0.07795, saving model to ./model/338-0.0779.hdf5\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.07795\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.07795\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.07795\n",
      "\n",
      "Epoch 00342: val_loss improved from 0.07795 to 0.07726, saving model to ./model/342-0.0773.hdf5\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.07726\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.07726\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.07726\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.07726\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.07726\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.07726\n",
      "\n",
      "Epoch 00349: val_loss improved from 0.07726 to 0.07639, saving model to ./model/349-0.0764.hdf5\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.07639\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.07639\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.07639\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.07639\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.07639\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.07639\n",
      "\n",
      "Epoch 00356: val_loss improved from 0.07639 to 0.07558, saving model to ./model/356-0.0756.hdf5\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.07558\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.07558\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.07558\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.07558\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.07558\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.07558\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.07558\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.07558\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.07558\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.07558\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.07558\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.07558\n",
      "\n",
      "Epoch 00369: val_loss improved from 0.07558 to 0.07511, saving model to ./model/369-0.0751.hdf5\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.07511\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.07511\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.07511\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.07511\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.07511\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.07511\n",
      "\n",
      "Epoch 00376: val_loss improved from 0.07511 to 0.07476, saving model to ./model/376-0.0748.hdf5\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.07476\n",
      "\n",
      "Epoch 00378: val_loss improved from 0.07476 to 0.07455, saving model to ./model/378-0.0746.hdf5\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.07455\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.07455\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.07455\n",
      "\n",
      "Epoch 00382: val_loss improved from 0.07455 to 0.07370, saving model to ./model/382-0.0737.hdf5\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.07370\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.07370\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.07370\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.07370\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.07370\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.07370\n",
      "\n",
      "Epoch 00389: val_loss improved from 0.07370 to 0.07268, saving model to ./model/389-0.0727.hdf5\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.07268\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.07268\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.07268\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.07268\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.07268\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.07268\n",
      "\n",
      "Epoch 00396: val_loss improved from 0.07268 to 0.07232, saving model to ./model/396-0.0723.hdf5\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.07232\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.07232\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.07232\n",
      "\n",
      "Epoch 00400: val_loss improved from 0.07232 to 0.07206, saving model to ./model/400-0.0721.hdf5\n",
      "\n",
      "Epoch 00401: val_loss improved from 0.07206 to 0.07181, saving model to ./model/401-0.0718.hdf5\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.07181\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.07181\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.07181\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.07181\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.07181\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.07181\n",
      "\n",
      "Epoch 00408: val_loss improved from 0.07181 to 0.07133, saving model to ./model/408-0.0713.hdf5\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.07133\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.07133\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.07133\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.07133\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.07133\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.07133\n",
      "\n",
      "Epoch 00415: val_loss improved from 0.07133 to 0.07121, saving model to ./model/415-0.0712.hdf5\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.07121\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.07121\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.07121\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.07121\n",
      "\n",
      "Epoch 00420: val_loss improved from 0.07121 to 0.07046, saving model to ./model/420-0.0705.hdf5\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.07046\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.07046\n",
      "\n",
      "Epoch 00423: val_loss improved from 0.07046 to 0.07043, saving model to ./model/423-0.0704.hdf5\n",
      "\n",
      "Epoch 00424: val_loss improved from 0.07043 to 0.07021, saving model to ./model/424-0.0702.hdf5\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.07021\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.07021\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.07021\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.07021\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.07021\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.07021\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.07021\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.07021\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.07021\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.07021\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.07021\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.07021\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.07021\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.07021\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.07021\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.07021\n",
      "\n",
      "Epoch 00441: val_loss improved from 0.07021 to 0.06994, saving model to ./model/441-0.0699.hdf5\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00447: val_loss improved from 0.06994 to 0.06935, saving model to ./model/447-0.0693.hdf5\n",
      "\n",
      "Epoch 00448: val_loss improved from 0.06935 to 0.06928, saving model to ./model/448-0.0693.hdf5\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.06928\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.06928\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.06928\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.06928\n",
      "\n",
      "Epoch 00453: val_loss improved from 0.06928 to 0.06915, saving model to ./model/453-0.0692.hdf5\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.06915\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.06915\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.06915\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.06915\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.06915\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.06915\n",
      "\n",
      "Epoch 00460: val_loss improved from 0.06915 to 0.06845, saving model to ./model/460-0.0684.hdf5\n",
      "\n",
      "Epoch 00461: val_loss improved from 0.06845 to 0.06840, saving model to ./model/461-0.0684.hdf5\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.06840\n",
      "\n",
      "Epoch 00488: val_loss improved from 0.06840 to 0.06829, saving model to ./model/488-0.0683.hdf5\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.06829\n",
      "\n",
      "Epoch 00523: val_loss improved from 0.06829 to 0.06707, saving model to ./model/523-0.0671.hdf5\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.06707\n",
      "\n",
      "Epoch 00567: val_loss improved from 0.06707 to 0.06698, saving model to ./model/567-0.0670.hdf5\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.06698\n",
      "\n",
      "Epoch 00606: val_loss improved from 0.06698 to 0.06665, saving model to ./model/606-0.0667.hdf5\n",
      "\n",
      "Epoch 00607: val_loss improved from 0.06665 to 0.06624, saving model to ./model/607-0.0662.hdf5\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 0.06624\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 0.06624\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(X,Y, validation_split=0.33,\n",
    "                    epochs=3500, batch_size=500, verbose=0, callbacks=[checkpointer,early_stopping])\n",
    "y_vloss = history.history['val_loss']\n",
    "y_acc = history.history['accuracy']\n",
    "x_len = np.arange(len(y_acc))\n",
    "plt.plot(x_len, y_vloss, 'o', c='red', markersize=3)\n",
    "plt.plot(x_len, y_acc, 'o', c='blue', markersize=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd84cf9-80bf-4c0a-b0a7-d84e3cfe926a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17906b55-172c-4b8c-b1c9-43cce9a08b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
