{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "307116d9-3125-4d01-8bd6-843eba294db4",
   "metadata": {},
   "source": [
    "# NLTK\n",
    "- NLTK 와 Spacy는 토크나이징에 많이 쓰이는 대표적인 라이브러리\n",
    "- 영어 텍스텡 대한 전처리 및 분석 도구\n",
    "- conda install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81194cb-93cb-440a-937f-fcda62828395",
   "metadata": {},
   "source": [
    "## 토크나이징(Tokenizing)\n",
    "- 텍스트에 대해 특정 기준 단위로 문장을 나누는 것\n",
    "- ex) 문장을 단어 기준으로 나누거나 전체 글을 문장 단위로 나눈 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ee58dd2-7b6b-4132-99f6-48f494bd3d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corpus(말뭉치) 설치 및 연동\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9606c6c-bd8c-4bb2-a2e0-c4fff147d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 데이터를 각 단어 기준으로 토크나이징\n",
    "# tokenize 모듈에서 word_tokenize 를 불러와서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b383fbd3-93a3-4944-8553-df0b2e2a3287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "385063dd-1950-461e-9740-11953286eabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'computer', 'science', ',', 'information', 'engineering', ',', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages', ',', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyzelarge', 'amounts', 'of', 'natural', 'language', 'data', '.']\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 정의 후, word_tokenize 함수에 적용하면, 구분된 리스트를 받을 수 있다 \n",
    "# 단어, 특수 문자 가 따로 구분된다 \n",
    "\n",
    "sentence = \"Natural language processing (NLP) is a subfield of computer science, \\\n",
    "information engineering, and artificial intelligence concerned with the interactions \\\n",
    "between computers and human (natural) languages, in particular how to program computers to process and analyze\\\n",
    "large amounts of natural language data.\"\n",
    "\n",
    "print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73262f0-6cd4-432a-afbd-15682789b1a1",
   "metadata": {},
   "source": [
    "### 문장 단위로 토크나이징\n",
    "\n",
    "1. 문단을 문장으로 토크나이징\n",
    "2. 1의 결과를 다시 단어로 나누기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0368eac7-73cd-47a0-98ff-a15d2796dd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural language processing (NLP) is a subfield of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyzelarge amounts of natural language data.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "paragraph = \"Natural language processing (NLP) is a subfield of computer science, \\\n",
    "information engineering, and artificial intelligence concerned with the interactions \\\n",
    "between computers and human (natural) languages, in particular how to program computers to process and analyze\\\n",
    "large amounts of natural language data.\"\n",
    "\n",
    "print(sent_tokenize(paragraph))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
